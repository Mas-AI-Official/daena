# ‚úÖ Task 6: TPU/GPU Flex (GCP-ready) - Complete

**Date**: 2025-01-XX  
**Status**: ‚úÖ **COMPLETE**

---

## üìä Summary

### Goal
Make Daena flexible with GPUs and new Google TPU/AI chips. This involves:
- Runtime flags (config/env for accelerator choice)
- Detecting availability
- Providing GCP deployment snippets

---

## ‚úÖ Changes Made

### 1. DeviceManager Verified ‚úÖ

**Status**: Already implemented and working

**File**: `Core/device_manager.py`

**Features**:
- ‚úÖ Automatic device detection (CPU, GPU, TPU)
- ‚úÖ Device selection based on configuration
- ‚úÖ Batch size optimization for TPU (128√ó factor)
- ‚úÖ Memory management and cost tracking
- ‚úÖ Supports PyTorch (CUDA), TensorFlow, and JAX (TPU)

**Configuration**:
```python
DeviceManager(
    prefer="auto",  # auto, cpu, gpu, tpu
    allow_tpu=True,
    tpu_batch_factor=128
)
```

### 2. Runtime Flags ‚úÖ

**Status**: Already implemented in settings

**File**: `backend/config/settings.py`

**Environment Variables**:
```bash
export COMPUTE_PREFER="auto"  # auto, cpu, gpu, tpu
export COMPUTE_ALLOW_TPU="true"
export COMPUTE_TPU_BATCH_FACTOR="128"
```

**Settings Integration**:
```python
compute_prefer: str = Field("auto", env="COMPUTE_PREFER")
compute_allow_tpu: bool = Field(True, env="COMPUTE_ALLOW_TPU")
compute_tpu_batch_factor: int = Field(128, env="COMPUTE_TPU_BATCH_FACTOR")
```

### 3. Device Availability Detection ‚úÖ

**Status**: Already implemented

**File**: `Core/device_manager.py`

**Detection Methods**:
- **CPU**: Always available (via psutil)
- **GPU**: 
  - PyTorch CUDA detection
  - TensorFlow GPU detection
  - nvidia-smi fallback
- **TPU**:
  - JAX TPU detection
  - Cloud TPU via environment variables (`TPU_NAME`, `TPU_ZONE`)

**Code**:
```python
def _detect_devices(self) -> None:
    # Always add CPU
    # Detect GPU (multiple methods)
    # Detect TPU (if allow_tpu=True)
```

### 4. GCP Deployment Templates Created ‚úÖ

#### Compute Engine Scripts

**File**: `deploy/gcp/compute-engine-gpu-setup.sh`
- Creates VM instance with GPU accelerators
- Installs NVIDIA drivers
- Configures Daena with GPU preference
- Sets up firewall rules

**File**: `deploy/gcp/compute-engine-tpu-setup.sh`
- Creates VM instance and TPU node
- Installs JAX for TPU support
- Configures Daena with TPU preference
- Sets up firewall rules

#### GKE Deployments

**File**: `deploy/gcp/gke-gpu-deployment.yaml`
- Kubernetes deployment for GPU pods
- Requests `nvidia.com/gpu` resource
- Node selector for GPU nodes
- LoadBalancer service

**File**: `deploy/gcp/gke-tpu-deployment.yaml`
- Kubernetes deployment for TPU pods
- TPU node selector (`cloud.google.com/gke-tpu-accelerator: v4-8`)
- ConfigMap for TPU configuration
- LoadBalancer service

#### Cluster Setup Scripts

**File**: `deploy/gcp/gke-cluster-gpu.sh`
- Creates GKE cluster with GPU node pool
- Installs NVIDIA device plugin
- Creates ConfigMap and Secrets
- Sets up autoscaling

**File**: `deploy/gcp/gke-cluster-tpu.sh`
- Creates GKE cluster with TPU node pool
- Configures TPU access
- Creates ConfigMap and Secrets
- Sets up autoscaling

#### CI/CD Integration

**File**: `deploy/gcp/cloudbuild-deploy.yaml`
- Cloud Build configuration
- Builds and pushes Docker image
- Deploys to GKE cluster
- Automated deployment pipeline

#### Documentation

**File**: `deploy/gcp/README.md`
- Comprehensive deployment guide
- Prerequisites and setup instructions
- Configuration options
- Cost estimates and optimization tips
- Troubleshooting guide

---

## üìã Files Created/Modified

### Created
1. `deploy/gcp/compute-engine-gpu-setup.sh` - GPU VM setup script
2. `deploy/gcp/compute-engine-tpu-setup.sh` - TPU VM setup script
3. `deploy/gcp/gke-gpu-deployment.yaml` - GKE GPU deployment
4. `deploy/gcp/gke-tpu-deployment.yaml` - GKE TPU deployment
5. `deploy/gcp/gke-cluster-gpu.sh` - GPU cluster setup script
6. `deploy/gcp/gke-cluster-tpu.sh` - TPU cluster setup script
7. `deploy/gcp/cloudbuild-deploy.yaml` - CI/CD deployment config
8. `deploy/gcp/README.md` - Comprehensive deployment guide

### Verified (Already Implemented)
1. `Core/device_manager.py` - ‚úÖ DeviceManager already implemented
2. `backend/config/settings.py` - ‚úÖ Runtime flags already configured
3. `Tools/daena_device_report.py` - ‚úÖ Device report tool exists
4. `memory_service/nbmf_encoder_production.py` - ‚úÖ DeviceManager integrated

---

## ‚úÖ Acceptance Criteria

- [x] **Runtime flags for accelerator choice**
  - ‚úÖ `COMPUTE_PREFER` environment variable (auto, cpu, gpu, tpu)
  - ‚úÖ `COMPUTE_ALLOW_TPU` environment variable
  - ‚úÖ `COMPUTE_TPU_BATCH_FACTOR` environment variable
  - ‚úÖ Settings integration via Pydantic

- [x] **Device availability detection**
  - ‚úÖ Automatic CPU detection (always available)
  - ‚úÖ GPU detection (PyTorch, TensorFlow, nvidia-smi)
  - ‚úÖ TPU detection (JAX, Cloud TPU via env vars)
  - ‚úÖ Device selection with fallback logic

- [x] **GCP deployment snippets**
  - ‚úÖ Compute Engine setup scripts (GPU & TPU)
  - ‚úÖ GKE deployment YAMLs (GPU & TPU)
  - ‚úÖ Cluster setup scripts (GPU & TPU)
  - ‚úÖ CI/CD integration (Cloud Build)
  - ‚úÖ Comprehensive documentation

---

## üîß Technical Details

### Device Selection Logic

```
1. Check COMPUTE_PREFER:
   - "auto" ‚Üí Select best available (TPU > GPU > CPU)
   - "tpu" ‚Üí Force TPU, fallback to GPU/CPU
   - "gpu" ‚Üí Force GPU, fallback to CPU
   - "cpu" ‚Üí Force CPU only

2. Detect available devices:
   - CPU: Always available
   - GPU: PyTorch ‚Üí TensorFlow ‚Üí nvidia-smi
   - TPU: JAX ‚Üí Cloud TPU env vars

3. Select device based on preference:
   - If preference available ‚Üí Use it
   - If not available ‚Üí Fallback chain
```

### GCP Deployment Options

#### Option 1: Compute Engine (VM-based)
- **GPU**: `compute-engine-gpu-setup.sh`
- **TPU**: `compute-engine-tpu-setup.sh`
- **Use Case**: Simple deployments, single instance

#### Option 2: Google Kubernetes Engine (GKE)
- **GPU**: `gke-cluster-gpu.sh` + `gke-gpu-deployment.yaml`
- **TPU**: `gke-cluster-tpu.sh` + `gke-tpu-deployment.yaml`
- **Use Case**: Production deployments, auto-scaling

### Device Detection Priority

1. **GPU Detection**:
   - PyTorch CUDA (primary)
   - TensorFlow GPU (fallback)
   - nvidia-smi (final fallback)

2. **TPU Detection**:
   - JAX devices (primary)
   - Cloud TPU env vars (`TPU_NAME`, `TPU_ZONE`) (fallback)

### Batch Size Optimization

- **TPU**: Batch size √ó 128 (optimal for TPU efficiency)
- **GPU**: Batch size √ó 4 (good GPU utilization)
- **CPU**: Batch size √ó 1 (no optimization)

---

## üß™ Testing

### Manual Verification
```bash
# Test device detection
python Tools/daena_device_report.py

# Test with different preferences
export COMPUTE_PREFER="gpu"
python Tools/daena_device_report.py

export COMPUTE_PREFER="tpu"
python Tools/daena_device_report.py

export COMPUTE_PREFER="cpu"
python Tools/daena_device_report.py
```

### GCP Deployment Test
```bash
# Test GPU setup
export GCP_PROJECT_ID="your-project-id"
chmod +x deploy/gcp/compute-engine-gpu-setup.sh
./deploy/gcp/compute-engine-gpu-setup.sh

# Test TPU setup
export GCP_PROJECT_ID="your-project-id"
chmod +x deploy/gcp/compute-engine-tpu-setup.sh
./deploy/gcp/compute-engine-tpu-setup.sh
```

---

## üìù Commit Message

```
feat: accelerator abstraction (CPU/GPU/TPU) + GCP templates

- Verified DeviceManager implementation (CPU/GPU/TPU detection)
- Verified runtime flags in settings (COMPUTE_PREFER, COMPUTE_ALLOW_TPU, COMPUTE_TPU_BATCH_FACTOR)
- Created GCP deployment templates:
  - Compute Engine setup scripts (GPU & TPU)
  - GKE deployment YAMLs (GPU & TPU)
  - Cluster setup scripts (GPU & TPU)
  - CI/CD integration (Cloud Build)
  - Comprehensive deployment guide

Files:
- Created: deploy/gcp/compute-engine-gpu-setup.sh
- Created: deploy/gcp/compute-engine-tpu-setup.sh
- Created: deploy/gcp/gke-gpu-deployment.yaml
- Created: deploy/gcp/gke-tpu-deployment.yaml
- Created: deploy/gcp/gke-cluster-gpu.sh
- Created: deploy/gcp/gke-cluster-tpu.sh
- Created: deploy/gcp/cloudbuild-deploy.yaml
- Created: deploy/gcp/README.md
- Verified: Core/device_manager.py (already implemented)
- Verified: backend/config/settings.py (runtime flags configured)
```

---

**Status**: ‚úÖ **TASK 6 COMPLETE**  
**Next**: All tasks complete! üéâ

