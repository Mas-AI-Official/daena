# ‚úÖ Daena Brain Training & Backend Integration - COMPLETE!

## üéØ What's Set Up

### 1. ‚úÖ **Training Infrastructure**
- **Script**: `training/train_daena_brain_local.py`
- **Method**: QLoRA with Unsloth (memory-efficient)
- **Base Model**: Qwen2.5-3B-Instruct (can be changed)
- **Output**: `D:\Daena\local_brain\adapters\daena_brain\`
- **Data**: `D:\Daena\local_brain\data\train.jsonl`

### 2. ‚úÖ **Backend Integration**
- **Auto-detection**: Backend checks for trained model (`daena-brain`) on startup
- **Priority**: Trained model > Default model > Fallback
- **Service**: `backend/services/local_llm_ollama.py` - Uses trained model automatically
- **Registry**: `backend/services/model_registry.py` - Registers trained model if available

### 3. ‚úÖ **Batch File Updates**
- **Status Check**: `LAUNCH_DAENA_COMPLETE.bat` shows Ollama and trained model status
- **Auto-detection**: Checks for `daena-brain` model on launch

## üìã Training Workflow

### Step 1: Install Dependencies
```powershell
cd D:\Ideas\Daena
call venv_daena_main_py310\Scripts\activate.bat
pip install unsloth transformers peft datasets bitsandbytes accelerate --upgrade
```

### Step 2: Prepare Training Data
Training data format (`D:\Daena\local_brain\data\train.jsonl`):
```json
{"instruction": "You are Daena...", "input": "", "output": "I am Daena..."}
{"instruction": "How do you manage departments?", "input": "", "output": "I coordinate..."}
```

The script auto-generates basic data if none exists.

### Step 3: Train
```powershell
python training/train_daena_brain_local.py
```

**Time**: 30-60 min (GPU) or several hours (CPU)

### Step 4: Create Ollama Model
```powershell
.\training\create_ollama_model.ps1
```

Or manually:
```powershell
C:\Users\masou\AppData\Local\Programs\Ollama\ollama.exe create daena-brain -f D:\Daena\local_brain\adapters\daena_brain\Modelfile
```

### Step 5: Update .env
Add to `.env`:
```env
TRAINED_DAENA_MODEL=daena-brain
DEFAULT_LOCAL_MODEL=qwen2.5:7b-instruct
```

### Step 6: Restart Daena
The backend will automatically:
1. Detect Ollama ‚úÖ
2. Check for `daena-brain` model ‚úÖ
3. Use trained model if available ‚úÖ
4. Fallback to default if not ‚úÖ

## üîß How It Works

### Backend Flow:
1. **Startup**: `model_registry.py` checks Ollama availability
2. **Model Detection**: Lists available models via `list_models()`
3. **Priority**: If `daena-brain` exists ‚Üí use it, else ‚Üí `qwen2.5:7b-instruct`
4. **Registration**: Registers model as "Daena Brain (Trained)" or "Local Ollama"
5. **Usage**: `local_llm_ollama.py` automatically uses trained model when available

### Code Integration:
- `backend/services/local_llm_ollama.py` - Checks for trained model first
- `backend/services/model_registry.py` - Registers trained model on startup
- `backend/main.py` - Uses `llm_service` which can use local Ollama
- `LAUNCH_DAENA_COMPLETE.bat` - Shows status on launch

## ‚úÖ Verification

### Check Training:
```powershell
# Verify model exists
dir D:\Daena\local_brain\adapters\daena_brain\
```

### Check Ollama Model:
```powershell
C:\Users\masou\AppData\Local\Programs\Ollama\ollama.exe list
# Should show: daena-brain
```

### Test Model:
```powershell
C:\Users\masou\AppData\Local\Programs\Ollama\ollama.exe run daena-brain "Hello, I am Daena"
```

### Check Backend Logs:
Look for:
- `‚úÖ Registered local Ollama model: daena-brain` (if trained)
- `‚úÖ Registered local Ollama model: qwen2.5:7b-instruct` (if not trained)

## üìÅ Files Created/Modified

### New Files:
- `training/train_daena_brain_local.py` - Training script
- `training/create_ollama_model.ps1` - Ollama model creation
- `training/TRAINING_SETUP.md` - Detailed training guide

### Modified Files:
- `backend/services/local_llm_ollama.py` - Auto-detects trained model
- `backend/services/model_registry.py` - Registers trained model
- `LAUNCH_DAENA_COMPLETE.bat` - Shows training status

## üéì Next Steps

1. **Collect Training Data**: Add more examples from Daena's interactions
2. **Fine-tune**: Adjust training parameters for better results
3. **Specialized Models**: Create models for specific tasks (decision-making, coordination)
4. **Continuous Learning**: Set up retraining pipeline

## üêõ Troubleshooting

**Model not found**: Run `ollama list` to verify model exists

**Backend not using trained model**: Check `.env` has `TRAINED_DAENA_MODEL=daena-brain`

**Training fails**: Ensure GPU is available or use smaller model (Qwen2.5-3B)

**Out of memory**: Reduce batch size or use 4-bit quantization (already enabled)

**Status**: ‚úÖ **READY FOR TRAINING!** Everything is set up and integrated. Just run the training script! üöÄ


