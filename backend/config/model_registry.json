{
  "model_registry": {
    "version": "1.0.0",
    "last_updated": "2024-12-15T00:00:00Z",
    "default_provider": "azure",
    "task_mappings": {
      "conversation": {
        "primary": {
          "provider": "azure",
          "deployment": "daena",
          "model": "gpt-4.1-2025-04-14",
          "max_tokens": 4000,
          "temperature": 0.7
        },
        "fallback": {
          "provider": "anthropic",
          "deployment": "claude-3-sonnet",
          "model": "claude-3-sonnet-20240229",
          "max_tokens": 4000,
          "temperature": 0.7
        }
      },
      "strategic_planning": {
        "primary": {
          "provider": "azure",
          "deployment": "daena",
          "model": "gpt-4.1-2025-04-14",
          "max_tokens": 8000,
          "temperature": 0.3
        },
        "fallback": {
          "provider": "anthropic",
          "deployment": "claude-3-opus",
          "model": "claude-3-opus-20240229",
          "max_tokens": 8000,
          "temperature": 0.3
        }
      },
      "code_generation": {
        "primary": {
          "provider": "azure",
          "deployment": "daena",
          "model": "gpt-4.1-2025-04-14",
          "max_tokens": 6000,
          "temperature": 0.2
        },
        "fallback": {
          "provider": "deepseek",
          "deployment": "deepseek-coder",
          "model": "deepseek-coder-33b-instruct",
          "max_tokens": 6000,
          "temperature": 0.2
        }
      },
      "analysis": {
        "primary": {
          "provider": "azure",
          "deployment": "daena",
          "model": "gpt-4.1-2025-04-14",
          "max_tokens": 6000,
          "temperature": 0.1
        },
        "fallback": {
          "provider": "anthropic",
          "deployment": "claude-3-sonnet",
          "model": "claude-3-sonnet-20240229",
          "max_tokens": 6000,
          "temperature": 0.1
        }
      },
      "creative_writing": {
        "primary": {
          "provider": "azure",
          "deployment": "daena",
          "model": "gpt-4.1-2025-04-14",
          "max_tokens": 4000,
          "temperature": 0.9
        },
        "fallback": {
          "provider": "anthropic",
          "deployment": "claude-3-haiku",
          "model": "claude-3-haiku-20240307",
          "max_tokens": 4000,
          "temperature": 0.9
        }
      },
      "decision_making": {
        "primary": {
          "provider": "azure",
          "deployment": "daena",
          "model": "gpt-4.1-2025-04-14",
          "max_tokens": 6000,
          "temperature": 0.1
        },
        "fallback": {
          "provider": "anthropic",
          "deployment": "claude-3-opus",
          "model": "claude-3-opus-20240229",
          "max_tokens": 6000,
          "temperature": 0.1
        }
      }
    },
    "deployment_status": {
      "azure": {
        "status": "active",
        "health": "healthy",
        "last_check": "2024-12-15T00:00:00Z",
        "latency_ms": 1458.51,
        "rate_limit": {
          "requests_per_minute": 3000,
          "tokens_per_minute": 150000
        }
      },
      "anthropic": {
        "status": "active",
        "health": "healthy",
        "last_check": "2024-12-15T00:00:00Z",
        "latency_ms": 2341.78,
        "rate_limit": {
          "requests_per_minute": 1000,
          "tokens_per_minute": 100000
        }
      },
      "deepseek": {
        "status": "active",
        "health": "healthy",
        "last_check": "2024-12-15T00:00:00Z",
        "latency_ms": 1892.34,
        "rate_limit": {
          "requests_per_minute": 500,
          "tokens_per_minute": 50000
        }
      },
      "gemini": {
        "status": "inactive",
        "health": "unknown",
        "last_check": "2024-12-15T00:00:00Z",
        "latency_ms": null,
        "rate_limit": {
          "requests_per_minute": 0,
          "tokens_per_minute": 0
        }
      },
      "grok": {
        "status": "inactive",
        "health": "unknown",
        "last_check": "2024-12-15T00:00:00Z",
        "latency_ms": null,
        "rate_limit": {
          "requests_per_minute": 0,
          "tokens_per_minute": 0
        }
      }
    },
    "performance_metrics": {
      "total_requests": 15420,
      "successful_requests": 15398,
      "failed_requests": 22,
      "success_rate": 99.86,
      "average_latency_ms": 1876.45,
      "total_tokens_used": 2847560,
      "cost_estimate_usd": 45.67
    },
    "routing_policy": {
      "primary_fallback": true,
      "load_balancing": false,
      "cost_optimization": true,
      "latency_threshold_ms": 5000,
      "retry_attempts": 2,
      "circuit_breaker": {
        "enabled": true,
        "failure_threshold": 5,
        "recovery_timeout_seconds": 300
      }
    }
  }
} 